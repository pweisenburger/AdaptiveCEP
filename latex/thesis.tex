\documentclass[article, type=bsc, colorback, accentcolor=tud8b, parskip=half, bibliography=totocnumbered]{tudthesis}

\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{graphicx}
\usepackage[backend=biber, style=numeric, sorting=none]{biblatex}

\lstset{basicstyle=\ttfamily}

\addbibresource{references.bib}

\newcommand{\comment}[1]{}

\begin{document}

\thesistitle{EventScala}{A Type-Safe, Distributed and Quality-of-Service-oriented Approach to Event Processing}
\author{Lucas Bärenfänger}
\referee{Prof. Dr. Guido Salvaneschi}{Pascal Weisenburger, M.Sc.}
\department{Fachbereich Informatik}
\group{Software Technology Group\newline Reactive Programming Technology}

\makethesistitle

\affidavit{Lucas Bärenfänger}

\tableofcontents

\newpage

\section{Abstract}
\label{sec:abstract}

\newpage

\section{Introduction}
\label{sec:introduction}

Event processing (EP) is now the leading paradigm for building applications that monitor and react to events as they happen.
In the corporate world, it is used in a variety of applications, e.g., business process management.
EP technologies are also deeply embedded in the financial sector.

Nevertheless, current EP solutions still suffer from shortcomings, three of which are addressed in this thesis.
For one, many EP solutions receive queries in the form of strings, just like it is common in the field of relational databases.
As a consequence, syntactically malformed or ill-typed queries are not detected at compile-time, allowing for them to fail at run-time.
Furthermore, many EP solutions are non-distributed, i.e., centralized solutions.
Therefore, they neither meet efficiency demands by leveraging parallelism nor do they cope with the distributed nature of event sources.
Lastly, while some research has been conducted on quality of service (QoS) in the EP domain, there appears to be no solution enabling queries to be explicitly annotated with QoS requirements.
However--especially in the case of real-time applications that make decisions--whether or not a query's requirements have been met during its execution might be crucial for the value and/or correctness of its result.

This thesis presents a type-safe, distributed and quality-of-service-oriented approach to EP.
As such, it explores ways to tackle the aforementioned issues.
Its contribution, the EventScala framework, features a domain-specific language (DSL) to express EP queries as well as so-called execution graphs to run them.
The DSL enables to express queries in a type-safe manner, thus, serves as a static shield against malformed or ill-typed queries.
It also allows for QoS requirements to be defined over queries in a fine-grained fashion, i.e., they can be defined over a query or its arbitrarily deeply nested subqueries.
To distributedly execute of a query, the primitives and operators it consists of are mapped to concurrently executing processing nodes that form a graph--the query's execution graph.
Each processing node of an execution graph continously monitors its performance and triggers user-defined action whenever a requirement is not met.

As its name suggests, EventScala is based on the technology stack of the Scala ecosystem.
Due to its flexible and extensible nature, Scala is known for its great support for building DSLs.
Therefore, the DSL is embedded into Scala, leveraging some of the features that make Scala a great host language, e.g., infix operator syntax and implicit conversions.
The execution graph is based on the Akka toolkit.
Akka's approach to concurrency programming is based on the actor model, thereby aiming to eliminate many of the difficulties commonly associated with the subject.
Moreover, Akka appears to be especially suited for developing an EP solution, as it already embodies several of the common characteristics of the domain.

It can be stated that expressing queries using the DSL as opposed to SQL-like strings is a superior approach.
One of the reasons for this is that statically checked queries are far less likely to fail at run-time.
Furthermore, running queries using an execution graph constitutes a way to benefit from the advantages of concurrent execution in the EP domain.
Finally, this thesis shows that the concept of queries being annotated with QoS requirements can be integrated at the language as well as at the execution level.

The remainder of this thesis is structured as follows.
Related work is presented in section \ref{sec:state_of_the_art}.
The state of the art of EP in general is covered in section \ref{sec:event_processing}, its language-level integration is discussed in section \ref{sec:ep_language_integration}, and sections \ref{sec:ep_distributed_execution} and \ref{sec:ep_qos} deal with distributed EP as well as QoS in the context of EP, respectively.
Section \ref{sec:eventscala} presents the EventScala framework, with section \ref{sec:case_class_rep} introducing the underlying case class representation, section \ref{sec:dsl} covering the DSL, section \ref{sec:execution_graph} discussing the execution graph and section \ref{sec:qos} outlining the QoS approach.
A simulation showcasing EventScala's capabilities is shown in section \ref{sec:simulation}.
The conclusion of this thesis is presented in section \ref{sec:conclusion}. 

\newpage

\section{State of the Art}
\label{sec:state_of_the_art}

\subsection{Event Processing (EP)}
\label{sec:event_processing}

Event processing (EP) has, according to Hinze, Sachs and Buchmann \cite{Hinze:2009:EAE:1619258.1619260}, become the ``paradigm of choice'' in ``many monitoring and reactive applications'', with application scenarios including traffic monitoring, fraud detection, supply chain management and many more.

This section is structured as follows.
Firstly, widely accepted terminology and concepts are described. Secondly, some EP solutions as well as the respective research papers are referenced.

Chandy and Schulte \cite{Chandy:2009:EPD:1594754} simply describe an event as ``something that happens''.
In \cite{Hinze:2009:EAE:1619258.1619260}, however, two more refined notions of events are introduced: ``change events'' (e.g., an object changing its position) and ``status events'' (e.g., a value yielded by a sensor).

After being observed and signaled, an event takes takes the form of an event instance, which corresponds to an event type.
An event instance is commonly represented as a tuple of values, with the type of each element of the tuple being defined in the associated event type.
For example, a temperature reading from some sensor ``X'' indicating 21 degrees Celsius in temperature might be represented by the event instance \lstinline{("X", 21)} with the event type being \lstinline{(String, Int)}.
For the sake of simplicity, the remainder of this text will refer to event instances as events.

Analogous to expressions in programming languages, which are either primitive values (e.g., \lstinline{true} or \lstinline{42}) or made up of other expressions that are combined by operators and functions (e.g., \lstinline{true && isThisAGoodNumber(42)}), events may be primitive events or compositions/derivations of primitive and/or other composite/derived events.
As defined in \cite{Hinze:2009:EAE:1619258.1619260}, ``composite events'' are ``aggregations of events'', whereas ``derived events'' are ``caused by other events'' and typically are ``at a different level of abstraction''.
As an example for the latter, a series of failed login attempts might cause an intrusion event.

Etzion and Neblett \cite{Etzion:2010:EPA:1894960} define an ``event stream (or stream)'' as a ``set of associated events'' that is ``often'' ``temporally ordered''.
A stream solely consisting of events of the same type is called a ``homogeneous stream''--as opposed to ``heterogeneous''.

Operators are defined over streams as opposed to individual events.
The \lstinline{or} operator, for example, represents the union of two streams, and places the events of both streams in one result stream.
The two streams the \lstinline{or} operator takes as operands can be viewed as its incoming streams, the result stream can be viewed as its outgoing stream.

Traditionally, two approaches to EP can be distinguished:

\begin{description}

\item[Stream processing (SP)]
typically features operators that resemble those of relational algebra, e.g., \lstinline{projection}, \lstinline{selection}, \lstinline{join}, etc.
SP queries are usually expressed in some SQL dialect and constitute so-called ``continuous queries''.
This term underlines an inversion of principles: In traditional database management systems (DBMSs), it is the data that is being persisted and not the queries. Continuous queries, however, are being persisted and run \emph{continuous}ly, while it is the data that can be thought of as flowing through.

\item[Complex event processing (CEP)]
typically features operators that resemble those of boolean algebra, e.g., \lstinline{and}, \lstinline{or}, \lstinline{not}.
Operators such as \lstinline{sequence} and \lstinline{closure} are common, too. CEP queries are usually expressed using rule languages.

\end{description}

Furthermore, there is another significant difference between SP and CEP.
As said, SP operators resemble those of relational algebra.
Some relational operators (e.g., \lstinline{join}), however, are blocking operators, in the sense that they are defined over finite sets of data and block execution until these are available in their entirety.
Streams, however, can be viewed as infinite sets of data.
As a consequence, in SP, the respective operators are not applied to streams directly.
Instead, they require their operand streams to be annotated with so-called windows, which are typically expressed ``in terms of time or number of tuples [i.e., events]'' \cite{Chakravarthy:2009:SDP:1550717}.
A window only contains a finite number of events of the respective stream.
So-called consumption modes are the counterpart of windows in CEP.
They are explained best through an example.
The CEP operator \lstinline{and}, for instance, is semantically ambiguous.
The query \lstinline{A and B} only specifies that an event of type \lstinline{A} should be correlated with an event of type \lstinline{B}.
However, given the events \lstinline{b1}, \lstinline{b2}, \lstinline{a1}, occurring in that order, it is not clear whether \lstinline{a1} should be correlated with \lstinline{b1} or \lstinline{b2}--this depends on the given consumption mode.
(See \cite{Chakravarthy:1994:CEA:645920.672994} for more information on consumption modes.)
One of the differences between windows and consumptions modes is that the former are applied to streams (i.e., operands) while the latter are applied to operators.
As pointed out in \cite{Chakravarthy:2009:SDP:1550717}, consumption modes ``can be loosely interpreted as load shedding, used from a semantics viewpoint rather than a QoS viewpoint'', as they essentially dictate which events have to be kept in memory and which ones can be dropped as they will not be part of any correlation.
To the best of my understanding, the same can be said about windows.

Many EP solutions do feature operators of both approaches.
However, with regards to the SP solutions I have looked at, CEP operators are usually treated as second-class citizens.
Esper \cite{esper}, for example, can be considered a SP engine, coming with a typical SQL dialect, EPL (Event Processing Language), for expressing queries.
Queries solely made up of CEP operators can be expressed using so-called \lstinline{pattern}s.
These can then be used as operands of SP operator (listing \ref{lst:epl1}).
It is not possible to use SP operators within a pattern, though (listing \ref{lst:epl2}).
Another solution, Flink \cite{flink}, which considers itself to be a ``stream processing framework'', also features CEP operators (e.g., sequence as \lstinline{followedBy})--but does so in a designated library, called FlinkCEP \cite{flinkcep}.

\begin{lstlisting}[
caption={In EPL, the \lstinline{join} operator (\lstinline{,}) can be applied to a \lstinline{pattern}.},
label={lst:epl1}]

// `lastEvent` forms a window, continuously containing the last event of the stream.
select * from
  Sensor1.std:lastEvent(), pattern[every (Sensor2 or Sensor3)].std:lastEvent()

\end{lstlisting}

\begin{lstlisting}[
caption={On the contrary, in EPL, the \lstinline{join} operator cannot be used within a \lstinline{pattern}.},
label={lst:epl2}]

// Invalid EPL!
select * from
  pattern[every (Sensor1 or (Sensor2.std:lastEvent(), Sensor3.std:lastEvent()))]

\end{lstlisting}

It is to be pointed out that the distinction between SP and CEP can be considered blurry, as many books and publications often use the terms SP and CEP in their broad sense, that is, EP in general.
SP and CEP do, however, pose different challenges when it comes to quality of service (QoS).
(See section 2.4. regarding their QoS-related differences.)
Refer to section 5 (``Analysis of Event vs. Stream Processing'') of \cite{Chakravarthy:2008:ESH:1385989.1385991} for another comparison of CEP an SP.

Moreover, the term event-driven architecture (EDA) represents another important concept in the domain of EP.
It is defined as the ``concept of being event-driven'', i.e., acting in response to an event, being applied to software.
In \cite{Chandy:2009:EPD:1594754}, the following ``five principles of EDA'' are identified:

\begin{description}

\item[Individuality]
Each event is transmitted individually, not as part of a batch.
\item[Push]
Events are pushed, not pulled, i.e., requested.
\item[Immediacy]
Events are being reacted to immediately after reception.
\item[One-way]
The type of communication is ``fire-and-forget'', events are neither being acknowledged nor replied to.
\item[Free of command]
An event never prescribes the action that will be taken upon reception.

\end{description}

Early EP solutions are HiPAC \cite{Dayal:1988:HPC:44203.44208}, SAMOS \cite{Gatziu:1996:SAO:901611}, Snoop \cite{Chakravarthy:1994:CEA:645920.672994} and SnoopIB \cite{Adaikkalavan:2006:SIE:1176530.1176536}.
To the best of my knowledge, these will give an impression of the developments from the late 1980s to the early 2000s.
Up-to-date solutions are, for example, Esper \cite{esper} and Flink \cite{flink}.

\subsection{EP \& Language Integration}
\label{sec:ep_language_integration}

This section starts out by examining and criticizing the way queries are typically expressed in EP solutions.
Then, the notion of domain-specific languages (DSLs) is introduced.
Lastly, it is described how DSLs are used to ease problems that are common in the context of relational databases, as there are analogous problems to be solved in the EP domain.

As pointed out in \cite{Schilling:2010:DHE:1827418.1827453}, ``there does not exist any generally accepted definition language for complex event processing''.
However, many EP solutions--especially those that rely on dialects of SQL for expressing queries--generally receive those in the form of strings, just as traditionally done in DBMSs.

In \cite{Leijen:1999:DSE:331960.331977}, Leijen and Meijer lay out why communicating SQL expressions in the form of ``unstructured strings'' is a bad approach.
To begin with, ``[p]rogrammers get no static safeguards against creating syntactically incorrect or ill-typed queries, which can lead to hard to find runtime errors''.
Furthermore, it is noted that the programmer at least needs to know the SQL dialect as well as the ``language that generates the queries and submits them''.
To underline these very points, the authors of \cite{Kabanov:2008:ETD:1411732.1411758} present ``a very simple example of an SQL query in Java'' that contains multiple errors.
The SQL query is embedded in Java as a \lstinline{String}.
Among other errors, it contains a misspelled SQL command.
Furthermore, it is stated that the assumptions made about the type of the column and the result set could be wrong.
As said, the problem is that, as described by Spiewak and Zhao \cite{Spiewak:2009:SLD:2127907.2127923}, the query is embedded ``within application code in the form of raw character strings''.
As ``[t]hese queries are unparsed and completely unchecked until runtime'', malformed queries do not cause the code they are embedded in to not compile but will cause trouble when being executed run-time.

To tackle this issue in the domain of traditional DBMSs, the contribution of \cite{Spiewak:2009:SLD:2127907.2127923} is a so-called domain-specific language (DSL)--named ScalaQL--``to make the host language compiler [i.e., scalac] aware of the query and capable of statically eliminating these runtime issues''.
(In fact, the contribution of the much earlier released publication of Leijen and Meijer \cite{Leijen:1999:DSE:331960.331977} is very similar.
Here, the host language is Haskell, whereas the problem domain is also relational databases, though.
They appear to be the first ones to ``show how to embed the terms and type system of another (domain-specific) programming language into the Haskell framework, which dynamically computes and executes programs written in the embedded language''.

To explain what DSLs are, it makes sense to turn to the book ``DSLs in Action'' by Ghosh \cite{Ghosh:2010:DA:1965333}, which appears to be the standard primer on the subject.
In it, one can find the following definition:

\emph{
``A DSL is a programming language that's targeted at a specific problem; other programming languages that you use are more general purpose.
It contains the syntax and semantics that model concepts at the same level of abstraction that the problem domain offers.''}

Furthermore, it is stated that--``[m]ore often than not''--DSLs are used by non-expert programmers.
For this to be possible, it is necessary that the DSL appeals to its target group by having ``the appropriate level of abstraction'', that is, it must embody the particular terminology, idioms, etc. of the respective domain.
This, however, leads to so-called ``limited expressivity''--``you can use a DSL to solve the problem of that particular domain only''.
As an example of limited expressivity, the author mentions that ``[m]athematicians can easily learn and work with Mathematica'' and ``UI designers feel comfortable writing HTML''.
However, one cannot, for example, ``build cargo management systems using only HTML''.

In his book, Ghosh further differentiates the notion of DSLs.
According to the author, there are internal as well as external DSLs.
Internal DSLs are also known as embdedded DSLs.
They are defined as follows:

\emph{``An internal DSL is one that uses the infrastructure of an existing programming language (also called the host language) to build domain-specific semantics on top of it.''}

\emph{``An external DSL is one that's developed ground-up and has separate infrastructure for lexical analysis, parsing technologies, interpretation, compilation, and code generation.''}

In \cite{Leijen:1999:DSE:331960.331977}, it is argued that internal DSLs ``expressed in higher order, typed [...] languages'' are better suited as a ``framework for domain-specific abstractions'' than external DSLs.
This is, according to the authors, due to the fact that programmers only have to know the host language as domain specific abstractions are made available as ``extension languages''.
Other advantages mentioned are the possibility to leverage other ``domain-sprecific libraries'' as well as the possibility to use the host language's infrastructure, e.g., its module and type system.
In \cite{Kabanov:2008:ETD:1411732.1411758}, more advantages of internal DSLs are stated, e.g., ``re-using the platform tooling, which in Java case [sic] includes compilers, advanced IDEs, debuggers, profilers, and so on''.
Furthermore, it is stated that development is much easier as it essentially ``boils down to writing an API''.

Finally, it is to be noted that Scala lends it self very well as a host language for internal DSLs.
For instance, Scala language features used in ScalaQL \cite{Spiewak:2009:SLD:2127907.2127923} include ``operator overloading, implicit conversions, and controlled call-by-name semantics''.
With ScalaQL deprecating SQL strings as a means of communication with DBMSs in the Scala ecosystem, it is the logical next step to deprecate SQL-like strings as a means of communication with EP solutions in the Scala ecosystem--by developing an internal DSL.
(Obviously, ScalaQL is just one of many DSLs doing so, another approach would be Slick by Lightbend (formerly Typesafe) \cite{slick}.)

\subsection{EP \& Distributed Execution}
\label{sec:ep_distributed_execution}

In \cite{Schilling:2010:DHE:1827418.1827453}, Schilling, Koldehofe, Rothermel and Pletat argue that ``distributing the handling of events'' is of growing importance, if only due to ``the emerging increase in event sources''.
It can be stated that other reasons for this trend are the need to exploit parallelism to meet increasing efficiency demands, avoiding single points of failure, and many more.

Academia has, in fact, proposed numerous approaches to distributed event processing, e.g, [8 - 16].
To the best of my knowledge, however, these have too few common characteristics to distill one reference model that represents academia's approach to distributed EP.
Furthermore, as pointed out in \cite{Schilling:2010:DHE:1827418.1827453}, ``there exists a gap between [...] academia and the industry'', that is, none of the approaches to distributed EP proposed have actually been picked up and used in practice.
One of the stated reasons for this circumstance is that EP technology ``in business applications'' needs ``to access context information related to business processes'' that ``often resides in centralized databases''.

As a consequence of both academia's propositions being too diverse to be adequately represented in this section as well as the lack of solutions originating in industry, I chose to introduce distributed EP theoretically, i.e., through an abstraction.
Afterwards, challenges that are present in this area of research are listed--along with references to publications that address these.

In \cite{Etzion:2010:EPA:1894960}, Etzion and Niblett introduce an abstraction called event processing network (EPN).
An EPN is made up of processing elements.
It is represented as a graph with the processing elements being the nodes of the graph.
Nodes can have ``input terminals'' and/or ``output terminals''.
Output terminals of one node may be connected to input terminals of other nodes, thus forming the edges of the graph.
An edge shows ``the flow of event instances through the network'', thus can be considered a stream.
There are the following types of processing elements:

\begin{description}

\item[Event producers]
introduce events into an EPN.
\item[Event consumers]
receive events from processing elements in an EPN.
\item[Event processing agents (EPAs)]
embody ``three logical functions'':

\begin{itemize}

\item
Filtering, i.e., selecting events for further processing
\item
Matching, i.e., ``[f]inding patterns among events'' and creating respective pattern events
\item
Derivation, i.e., deriving new events from the output of the pattern step

\end{itemize}

\item[Global state elements]
``represent stateful data that can be read by event processing agents when they do their work''.
\item[Channels]
may be used to connect processing elements instead of edges, as the behavior of channels may be defined explicitly.

\end{description}

Figure \ref{fig:epn} depicts an exemplary EPN.

\begin{figure}
\caption{An exemplary EPN (Inspired by figure 2.7 on page 43 of ``Event Processing in Action'' \cite{Etzion:2010:EPA:1894960})}
\label{fig:epn}
\includegraphics[width=0.5\textwidth]{images/epn.png}
\centering
\end{figure}

It is to be stressed that an EPN diagram is an abstraction, comprised of ``platform-independent definition elements''.
It does not assume a distributed implementation.
After the introduction of the EPN concept, the authors lay out the ``[i]mplementation perspective'', in which the graph has to be materialized onto what are being called ``runtime artifacts'', resulting in a ``runtime system''.
Usually, there is no ``one-to-one correspondence'' between the processing elements of an EPN and the runtime artifacts of a respective implementation.
With regards to this, two ``extremes'' are being described:

\begin{itemize}
\item
The entire EPN may be represeted by one runtime artifact, i.e., one centralized runtime system.
\item
Each EPA is represented by one runtime artifact.
These distribute events between each other and ``can be placed on different server[s], allowing much of the [...] work to be performed in parallel.''
\end{itemize}

To the best of my knowledge, the second scenario can be considered a good example for distributed EP, even though there are obviously many ways to map EPAs to runtime artifacts, several of which might also be considered distributed approaches.

In the chapter ``EPA assignment optimization''--which is concerned with mapping ``logical functions [i.e., EPAs] to physical runtime artifacts''--the authors mention parallel and distributed processing explicitly.
Parallel processing is considered ``[o]ne of the major ways to achieve [...] performance metrics''.
Then, three levels of parallelism are introduced, that is, using multiple threads in one core, using multiple cores and using multiple machines.
However, finding out ``which activities should be run in parallel'' is listed as a ``difficult'' challenge.
Regarding distributed processing, it is stated that ``moving the processing close to the producers and consumers'' constitutes an optimization method.
Furthermore, ``[p]artitioning''--the practice of grouping EPAs so they eventually ``execute together [i.e., in parallel]'' when mapped to runtime artifacts--is introduced and considered ``key'' to both parallel execution and distributed execution.
``Stratification'', a partitioning approach in which EPAs are assigned to so-called ``strata'' is then explained: ``If \lstinline{EPA1} produces events that are consumed by \lstinline{EPA2}, then \lstinline{EPA2} is placed in a higher stratum.''

Regarding the aforementioned challenge of parallelization, \cite{stratified}, \cite{Farroukh:2009:PEP:1619258.1619269}, \cite{Khandekar:2009:COS:1656980.1657002} and \cite{Hirzel:2012:PCP:2335484.2335506} present different approaches.
Furthermore, the previously mentioned ``moving [of] the processing close to the producers and consumers'' poses another challenge, especially with mobile producers/consumers.
In \cite{Pietzuch:2003:FEC:1515915.1515921}, \cite{1203579} and \cite{Ottenwalder:2013:MOM:2488222.2488265}, interesting approaches with regards to this are presented.
Moreover, it appears that a good amount of the solutions to distributed EP proposed by academia, e.g., \cite{792159}, \cite{Pietzuch:2003:FEC:1515915.1515921}, \cite{1203579} and \cite{Farroukh:2009:PEP:1619258.1619269}, are built upon loosely-coupled publish/subscribe systems (or pub/sub systems), which constitute a related field of research themselves.
Also, for events to be put into time-based windows (as sometimes required by the SP operator \lstinline{join}) or for them to be ordered properly (as demanded by the CEP operator \lstinline{sequence}), they need to be properly timestamped.
Timestamping is a well-studied challenge in distributed systems in general and many approaches to tackle it have been proposed.
\cite{792159} presents an interesting solution specifically aimed at distributed EP, leveraging a combination of NTP-synchronized local clocks and heartbeat events.

\subsection{EP \& Quality of Service}
\label{sec:ep_qos}

In \cite{quality}, Appel, Sachs and Buchmann note that ``[f]uture software systems'' have to be ``responsive to events'' in order to ``adapt [...] software to enhance business processes''.
As an example, they mention logistics processes that must be altered according to incoming updates on traffic.
Furthermore, it is stressed that in such a scenario, in which critical business processes are triggered by events, ``[t]he trust in such [...] systems depends to a large extent on the Quality of Service (QoS) provided by the underlying event system''.
The definition of QoS metrics as well as finding the means to monitor those is considered a ``major challenge''.

This section is structured as follows.
Firstly, QoS metrics that have been identified for publish/subscribe systems--which also apply to EP in general--are described.
Secondly, QoS metrics that are specific to SP or CEP are presented.

As--according to \cite{quality}--``[f]or the [underlying] communication [...] the paradigm of choice is publish/subscribe'' \cite{quality}, it makes sense to take a look at \cite{1648910}, in which Behnel, Fiege and Mühl identify generic QoS metrics for publish/subscribe-based systems.
It is to be noted, however, that the authors of \cite{quality} recommended to refrain from considering such generic QoS metrics.
Instead, they propose to first identify ``functionality needs'' of an EP solution and then, based on this, compile a list of specific QoS requirements--``rather than building a Swiss army knife EBS [i.e., event-based system] supporting all imaginable [...] QoS needs''.
Nevertheless, the following paragraphs summarize some of the generic QoS metrics presented in \cite{1648910}. 
Before that, a short description of the publish/subscribe paradigm is quoted, also from \cite{1648910}:

\emph{
``The system model of the publish-subscribe communication paradigm is surprisingly simple.
[... There are] three roles: publishers, subscribers and brokers.
Publishers [...] provide information, advertise it and publish notifications about it.
Subscribers [...] specify their interest and receive relevant information when it appears.
Brokers mediate between the two by selecting the right subscribers for each published notification. [...]
There can be a single centralized broker, a cluster of them or a distributed network of brokers.''}

Although the QoS metrics listed below were originally put together ``in the context of distributed and decentralized publish-subscribe systems'', they do also apply to EP, since--as mentioned before--the underlying communication of many distributed EP solutions is based on the publish/subscribe paradigm.
In order to interpret these QoS metrics in the sense of EP, one can simply think of event producers, event consumers and EPAs (as found in EPNs) whenever publishers, subscribers and brokers (as found in publish/subscribe systems) are mentioned.
Moreover, statements about publishers and subscribers do not only apply to event producers and event consumers, respectively, but also to EPAs, as they also consume and produce event streams.
For example, a statement such as ``Publishers annotate notifications they emit with priorities'' can be interpreted as ``Event producers and EPAs annotate events they produce with priorities''.

\begin{description}

\item[Latency]
It is stated that ``[s]ubscribers request a publisher that is within a maximum latency bound''.
An ``end-to-end latency'' between a publisher and a subscriber ``depends on the number of [...] hops between them'' as well as on the time each broker takes to deal with a notification.
However, in a distributed setting, ``measured lower bounds'' may at best ``give hints'' about whether some latency requirement can be met--not ``absolute guarantees''.
Preallocating paths is mentioned as a way to deal with latency requirements.

\item[Bandwidth]
It is described that publishers announce upper/lower bounds regarding the stream they produce, whereas subscribers ``restrict the maximum stream of notifications they want to receive''.
It is recommended to consider bandwidth at the ``per-broker'' level.
Given that ``each broker knows the bandwidth it can make locally available to the infrastructure'', an upper-bound for an entire path can be estimated, allowing for routing ``based on the highest free bandwidth''.

\item[Message priorities]
It is proposed that publishers annotate the notations they produce with relative or absolute priorities, denoting their importance compared to other notifications produced either by themselves or elsewhere, respectively.
Subscribers, on the other hand, specify priorities regarding their subscriptions.
At the ``per-broker'' level, priorities ``can be used to control the local queues of each broker'', resulting in the ``end-to-end application'' of the priorities along the entire path.
This is, according to the authors, commonly implemented by letting notifications with higher priorities overtake those with lower priorities at each broker.

\item[Delivery guarantees]
While subscribers announce ``which notifications they must receive'', and where they are sensitive to duplicates, it is stated that publishers ``specify if subscribers must receive certain notifications''.
A simple approach that is mentioned is to simply let the system know which messages can be discarded.
More sophisticated approaches concern ``the completeness and duplication of delivery'', i.e., subscribers may receive notifications that are directed to them ``at least once'', ``at most once'', or ``exactly once''.
While meshing is listed as a way to achieve ``at least once'', it comes at the price of ``increasing the message overhead''.
Disconnected subscribers are yet ``[a]nother problem'', as they might stay disconnected, in which case ``at least once'' cannot be guaranteed, no matter for how long the notifications are buffered.

\item[Notification order]
It is explained that ``[t]he order in which notifications arrive'' is of significance in some cases while it is not in other cases.
With centralized ordering, ``ordering is [considered] easy to achieve''.
However, ``distributed ordering of events coming from different sources'' is described as problematic.
Deploying a ``central broker to enforce a global ordering'' is mentioned as a ``generic approach'' to tackle this challenge, imposing a ``limit'' on the ``scalability of the overall infrastructure'', though.

\item[Validity interval]
The importance of the infrastructure to know ``how long a notification stays valid'' is stressed.
It is explained that this is specified either ``in terms of time'' of ``by the arrival of later messages''.
Specifying that ``only the most recent event is of interest'' through ``follow-up messages'' is described as an example of the latter.
This is called an ``efficient approach'', as it allows for the infrastructure to ``shorten its queues in high traffic situations''.

\end{description}

When interpreting the above list of QoS metrics in terms of EP, it becomes evident that these metrics can be applied to both SP as well as CEP.
(As said, brokers are to be thought of as EPAs, and it has not been specfied whether these EPAs perform SP or CEP operations.)
There are, however, QoS metrics that specifically apply to either SP or CEP.
Some have been identified in \cite{Buchmann:2012:CEA:2413516.2413519} by Buchmann, Appel, Freudenreich, Frischbier and Guerrero.

SP-specific QoS metrics (listed in the section ``QoS of Stream Processing'' of \cite{Buchmann:2012:CEA:2413516.2413519}) include:

\begin{description}

\item[Timeliness]
One the one hand, it is stated that applications relying on SP ``typically have timing constraints to meet'', thus, the timeliness of the ``continuous processing of incoming events'' is considered ``one of the most relevant QoS requirements''.
On the other hand, however, many of these applications may ``tolerate approximate results''.
According to the authors, these circumstances suggest a ``common'' ``trade-off'', i.e., ``accuracy for timeliness''.
To the best of my understanding, an example of this trade-off would be favoring some less precise filter that therefore executes quickly over some more precise and more time-consuming filter.

\item[Throughput]
With regards to timeliness, ``achievable throughput'' is considered a ``closely related QoS metric''.
SP solutions are said to ``attempt to optimize'' their ``continuous query execution'' in order to achieve maximum throughput.
As load shedding is regarded as ``often'' being the ``only practical approach'', the result is, again, the ``trade-off of accuracy for timeliness''.
(The authors stress that the expected timeliness as well as the expected accuracy must be specified when designing a business process that relies on the SP.)

\item[Order]
Whether events may be processed out of order is listed as an ``application dependent'' ``issue''.

\end{description}

CEP-specific QoS metrics (listed in the section ``QoS of Event Composition'' of \cite{Buchmann:2012:CEA:2413516.2413519} include:

\begin{description}

\item[Order]
Establishing an ``ordering between events'' can be considered the most important QoS metric, as ``achievable QoS [...] depends largely on the possibility'' to be able to do so.
As an example of an operator requiring events to be ordered, the \lstinline{sequence} operator--``which is part of most [CEP] event algebras''--is mentioned.
Furthermore, it is stated that the ``natural ordering'' is time-based, which, according to the authors, is no problem if ``there is only one central clock'' as well as only one event occurring every clock tick.
If, however, there may be ``multiple events'' occurring at the same point in time, being ``time-stamped by different clocks'', establishing a total order is said to be impossible.
Lastly, it is explained that the granularity of timestamps plays a major role when it comes to timestamping:
Events that might have been distinguishable with fine-grained timestamps might no be distinguishable when being timestamped more coarsely.

\item[Delay/loss of messages]
The delay or loss of messages is described as a ``source of ambiguity''.
As an example, it is explained that it is impossible to determine that an event ``did not occur in a given interval'' unless it can be asserted that the event in question is neither delayed nor lost.
With regard to bounded networks, the authors refer to the 2g-precedence model as a possibility to tackle this challenge.
(An explanation of this model can be found in \cite{792159}.)
With regard to unbounded networks--``such as the internet''--they refer to \cite{792159}, i.e., an approach based on the the injection of ``heartbeat events from an outside time-service'' which assumes that events ``in the same channel do not overtake each other''.

\end{description}

\newpage

\section{EventScala}
\label{sec:eventscala}


\subsection{Case Class Representation}
\label{sec:case_class_rep}

At the heart of the EventScala framework is the case class representation of queries.
Thanks to it, EventScala's DSL and EventScala's execution graph can be thought of as separate modules that do not depend on each other in any way.
On the one hand, using the DSL to express a query results in the case class representation of that query.
On the other hand, executing a query using the execution graph requires a case class representation of said query.
However, a case class representation of a query does neither have to be obtained using the DSL nor does the query it represents have to be executed using the execution graph.
In fact, one could, for example, use the DSL to obtain the case class representation of a query and then generate a SQL-like string from it to execute it using Esper.
Likewise, one could develop a different DSL or even type out the case class representation of a query by hand and then pass it to the execution graph to be run.
Essentially, EventScala's case class representation is a type-safe and platform-independent way to encode queries for EP systems in Scala.

In this section, EventScala's case class representation is presented in great detail.
To this end, the hierarchy and structure of the traits and case classes that make up the case class representation of queries is explained.

At the top of the hierarchy, there is the \lstinline{Query} trait, which only specifies that extending classes have to have a field \lstinline{requirements}, representing a set of QoS requirements that were specified for the respective query.
(Refer to the end of this section as well as section 3.5 for more information on QoS requirements.)

As described in section 2.1, events are commonly represented by tuples of values, i.e., an event consisting of n values would be represented by a n-tuple.
In EventScala, an event consists of at least 1 element and at most 6 elements.
Analogously, the \lstinline{Query} trait is extended by the traits \lstinline{Query1}, \lstinline{Query2}, ..., \lstinline{Query6}, each representing a query that results in a stream of events consisting of 1, 2, ..., 6 elements, respectively.
The traits \lstinline{Query1}, \lstinline{Query2}, ..., \lstinline{Query6} do not specify any additional fields.
They do, however, take 1, 2, ..., 6 type parameters, respectively, specifying the types of the elements of the events of the respective streams they represent.
\lstinline{Query2[String, Int]} is, for example, the type of a query that results in a stream of events consisting of two elements: a \lstinline{String} and an \lstinline{Int}.

A query usually consists of nested applications of operators over primitives.
For example, one might subscribe to a stream of events consisting of a single \lstinline{Int}, resulting in a \lstinline{Query1[Int]}, as well as to a stream of events consisting of two \lstinline{String}s, resulting in a \lstinline{Query2[String, String]}.
One might then apply the \lstinline{join} operator to these two stream subscriptions, resulting in a \lstinline{Query3[Int, String, String]}.
Afterwards, one could decide to drop the second \lstinline{String} using the \lstinline{dropElem3} operator, resulting in a \lstinline{Query2[Int, String]}.
When picturing this query as a graph (as illustrated in figure \ref{fig:query}), the \lstinline{dropElem3} operator would be the root node, having one child node, i.e., the \lstinline{join} operator, which, in turn, would have two child nodes, i.e., the two stream subscriptions, which would represent the leaves of the graph.
(This is actually exactly what EventScala's execution graph for this query would look like.)
Analogously, the application of the \lstinline{dropElem3} operator can be thought of as a unary query--unary in the sense that it has one subquery.
Furthermore, the application of the \lstinline{join} operator can be thought of as a binary query--binary in the sense that it has two subqueries.
Lastly, the subscription to a stream can be thought of as a leaf query--leaf in the sense that it has no child queries.
As a matter of fact, in EventScala, every query can be classified into being either a leaf, a unary or a binary query.
Therefore, there exist three traits \lstinline{LeafQuery}, \lstinline{UnaryQuery} (specifying one field,  \lstinline{sq} (\lstinline{s}ub\lstinline{q}uery), of type \lstinline{Query}) and \lstinline{BinaryQuery} (specifying two fields, \lstinline{sq1} and \lstinline{sq2}, both of type \lstinline{Query}).
All three traits extend the trait \lstinline{Query}.

\begin{figure}
\caption{A conceptual depiction of a \lstinline{Query}}
\label{fig:query}
\includegraphics[width=0.5\textwidth]{images/query.png}
\centering
\end{figure}

In the previous paragraph, it has been hinted that in EventScala, one might subscribe to streams or make use of the operators \lstinline{join} as well as \lstinline{dropElem3}.
For the sake of completeness, find below the list of all primitives (i.e., leaf queries) and operators (i.e., unary and binary queries) available.

Leaf queries, i.e., traits extending \lstinline{LeafQuery}:

\begin{description}

\item[StreamQuery]
A \lstinline{StreamQuery}expresses a subscription to a stream.
The trait \lstinline{StreamQuery} specifies one field of type \lstinline{String}, \lstinline{publisherName}, for the name of the publisher that is the source of the stream.

\item[SequenceQuery]
A \lstinline{SequenceQuery} expresses a subscription to two streams with the CEP operator \lstinline{sequence} being applied to them.
The trait \lstinline{SequenceQuery} specifies two fields of type \lstinline{NStream}, \lstinline{s1} and \lstinline{s2}.
A \lstinline{NStream} is essentially a \lstinline{Stream}, however, it is ``\lstinline{N}ot a query'', i.e., not extending the trait \lstinline{Query}.
If \lstinline{NStream} would be a query, then \lstinline{s1} and \lstinline{s2} would represent its subqueries, making \lstinline{Sequence} a binary query rather than a leaf query.

\end{description}

Unary queries, i.e., traits extending \lstinline{UnaryQuery}:

\begin{description}

\item[FilterQuery]
A \lstinline{FilterQuery} expresses the application of the SP operator \lstinline{where}.
The \lstinline{FilterQuery} trait specifies one field of type \lstinline{Event => Boolean}, \lstinline{cond}, for the filter predicate.
The field for the subquery representing the operator's input stream is specified by the extending classes.

\item[DropElemQuery]
A \lstinline{DropElemQuery} expresses the application of the operator that EventScala offers instead of the EP operator \lstinline{select}.
While \lstinline{select} lets one select which elements of the events of the operator's input stream to keep, the \lstinline{dropElem} operator lets one specify which element to drop.
The \lstinline{DropElemQuery} trait specifies no fields.
Which element of the events of the operator's input stream is to be dropped is specified through the extending classes' names, e.g., \lstinline{DropElem1Of2}.

\item[SelfJoinQuery]
A \lstinline{SelfJoinQuery} expresses the application of the SP operator \lstinline{join} but with one stream representing both of the operator's input streams.
The \lstinline{SelfJoinQuery} trait specifies two fields of type \lstinline{Window}, \lstinline{w1} and \lstinline{w2}, for the windows that are applied to the operator's input streams.
The field for the subquery representing both of the operator's input streams is specified by the extending classes.

\end{description}

Binary queries, i.e., traits extending \lstinline{BinaryQuery}:

\begin{description}

\item[JoinQuery]
A \lstinline{JoinQuery} expresses the application of the SP operator \lstinline{join}.
The \lstinline{JoinQuery} trait specifies two fields of type \lstinline{Window}, \lstinline{w1} and \lstinline{w2}, for the windows that are applied to the operator's input streams.
The fields for the two subqueries representing the operator's input streams are specified by the extending classes.

\item[ConjunctionQuery]
A \lstinline{ConjunctionQuery} expresses the application of the CEP operator \lstinline{and}.
The \lstinline{ConjunctionQuery} trait specifies no fields.
The fields for the two subqueries representing the operator's input streams are specified by the extending classes.

\item[DinjunctionQuery]
A \lstinline{DisjunctionQuery} expresses the application of the CEP operator `or`.
The \lstinline{DisjunctionQuery} trait specifies no fields.
The fields for the two subqueries representing the operator's input streams are specified by the extending classes.

\end{description}

Up to this point, a hierarchy of traits but not one case class has been presented.
The case class representation of a query is, however, made up of (possibly nested) case classes.
These case classes have the following in common:

\begin{itemize}

\item
They extend exactly one of the traits \lstinline{Query1}, \lstinline{Query2}, ..., \lstinline{Query6}, indicating the number and types of the elements of the events of the resulting stream.

\item
They extend exactly one of the traits \lstinline{StreamQuery}, \lstinline{SequenceQuery}, \lstinline{FilterQuery}, \lstinline{DropElemQuery}, \lstinline{SelfJoinQuery}, \lstinline{JoinQuery}, \lstinline{ConjunctionQuery} and \lstinline{DisjunctionQuery}, indicating what kind of primitive or operator application they represent.

\end{itemize}

For example, the case class \lstinline{Stream1[A]} extends the trait \lstinline{Query1[A]}, indicating that it represents a stream of events consisting of 1 element of the generic type \lstinline{A}, as well as the trait \lstinline{StreamQuery}, indicating that it represents a subscription to a stream, i.e., a primitive.
It has a field \lstinline{publisherName} as specified by the trait \lstinline{StreamQuery} as well as a field \lstinline{requirements} as specified by the trait \lstinline{Query}.
\lstinline{Conjunction12[A, B, C]}, to provide another example, extends the trait \lstinline{Query3[A, B, C]}, indicating that it represents a stream of events consisting of 3 elements of the generic types \lstinline{A}, \lstinline{B} and \lstinline{C}, respectively, as well as the trait \lstinline{ConjunctionQuery}, indicating that it represents an application of the \lstinline{and} operator.
Obviously, it also has the field \lstinline{requirements}.

More interestingly, though, the case class \lstinline{Conjunction12[A, B, C]} also has two fields (\lstinline{sq1} of type \lstinline{Query1[A]} and \lstinline{sq2} of type \lstinline{Query2[B, C]}) for the subqueries representing the \lstinline{and} operator's two input streams, which--against one's intuition--are not specified in the \lstinline{ConjunctionQuery} trait.
The reason for this is that while every case class extending \lstinline{ConjunctionQuery} does have two fields named \lstinline{sq1} and \lstinline{sq2}, their types are always different.
For the case class \lstinline{Conjunction11[A, B]}, their types are \lstinline{Query1[A]} and \lstinline{Query1[B]}, respectively, and for \lstinline{Conjunction21[A, B, C]}, to provide another example, they are \lstinline{Query2[A, B]} and \lstinline{Query1[C]}, respectively.
This hints at the biggest shortcoming of EventScala:
As it is not possible to abstract over the length of type parameter lists in Scala, one cannot define one trait (like \lstinline{trait Query[A, B, ...]}) for queries in general, but has to define one separate trait (e.g., \lstinline{Query1[A]}, \lstinline{Query2[A, B]}, and so forth) for queries representing streams of events consisting of 1 element, 2 elements, and so forth.
(Tuples actually suffer from the same shortcoming: \lstinline{Tuple1[+T1]}, \lstinline{Tuple2[+T1, +T2]}, and so forth, are all defined separately in the Scala standard library.)
To avoid a ridiculous amount of code repetition, in EventScala, events can consist of at most 6 elements.
This seemingly small number does not only call for the 6 separate traits \lstinline{Query1[A]} to \lstinline{Query6[A, B, C, D, E, F]}, though, but also for--for example--15 separate case classes extending the \lstinline{SequenceQuery} trait as well as, to provide the most extreme example, for 36 case classes extending the \lstinline{DisjunctionQuery} trait.
Any future work on this project should aim to solve this issue, maybe by representing events and queries with \lstinline{HList}s, which encode the types of their members (which can be \lstinline{H}eterogenuous, i.e., of different types) in their type. They are provided by the popular Scala library Shapeless \cite{shapeless}, a ``type class and dependent type based generic programming library for Scala''.

At this point, EventScala's case class representation has been explained to an extent that it makes sense to present an example query in case class representation (listing \ref{lst:query}).

\begin{lstlisting}[
caption={Case class representation of the query depicted in figure \ref{fig:query}},
label={lst:query}]
val sampleQuery1: Query2[Int, String] =
  DropElem3Of3[Int, String, String](
    Join12[Int, String, String](
      Stream1[Int]("X", Set.empty),
      Stream2[String, String]("Y", Set.empty),
      SlidingTime(42),       // Sliding window of 42 seconds
      TumblingInstances(21), // Tumbling window of 21 events
      Set.empty),
    Set.empty)
\end{lstlisting}

The avid reader has certainly noticed that this is the case class representation of the query that has been informally described and illustrated as a graph previously in this section (figure \ref{fig:query}).
It is to be stressed that this is a type-safe representation of said query.
(This point will be discussed in detail in section 3.3.)
Also, it is to be stressed again that it is a platform-independent representation, i.e., it neither encodes data specific to the DSL that generated it nor does it encode data that is specific to the EP solution that will execute it.

Lastly, as the title of this thesis suggests, EventScala is a quality-of-service-oriented approach to EP.
As such, it allows for QoS requirements, i.e., run-time requirements, to be expressed with each query.
One might have noticed that the \lstinline{sampleQuery} above contains the expression \lstinline{Set.empty} four times.
At these four points, it would have been possible to define a set of requirements (of type \lstinline{Set[Requirement]}).
When picturing the query as a graph once again, it becomes clear that requirements can be defined over every node of the graph.
EventScala features two kinds of requirements, \lstinline{FrequencyRequirement}s and \lstinline{LatencyRequirement}s.
(These will be discussed in greater detail in section 3.5.)
It is to be noted, however, that the case classes representing these requirements are not platform-independent.
They do not just contain the specification of the respective requirement but also a callback closure that defines what to do whenever the respective requirement is not met during the execution of the query.
The fact that this callback closure is being passed data about the processing node that is responsible for executing the query in EventScala's execution graph is what breaks platform independence.
I chose to go this way as platform independence with regards to QoS requirements is somewhat pointless as--to the best of my knowledge--there are no other EP solutions that are able to work with such requirements.
Listing \ref{lst:query2} shows another example query, representing a simple stream subscription that is being applied to a filter, with the stream being required to emit at least 2 events every 5 seconds.

\begin{lstlisting}[
caption={Case class representation of a query that specifies a QoS requirement},
label={lst:query2}]
val sampleQuery2: Query2[Int, Boolean] =
  Filter2[Int, Boolean](
    Stream2[Int, Boolean](
      "Z",
      // If not at least 2 events are emitted every 5 seconds,
      // "Problem!" will be printed to the console.
      Set(FrequencyRequirement(GreaterEqual, 2, 5, _ => println("Problem!")))),
    // This filter predicate does not filter out any event. :)
    _ => true,
    // No QoS requirements are defined over the filter.
    Set.empty)
\end{lstlisting}

\subsection{Domain-Specific Language}
\label{sec:dsl}

EventScala's DSL for expressing queries for EP systems sets out to achieve in the domain of EP what ScalaQL and other DSLs achieved for relational databases, i.e., ``statically eliminating [...] runtime issues'' \cite{Spiewak:2009:SLD:2127907.2127923} caused by ``syntactically incorrect or ill-typed queries'' \cite{Leijen:1999:DSE:331960.331977}.
EventScala's DSL can be classified as an internal DSL.
With EventScala being a Scala framework, its host language is obviously Scala.

This section is structured as followed. 
At first, the DSL is presented from a user's perspective, i.e., an overview of its features is given and advantages are pointed out.
Then, notable parts of its implementation are discussed, e.g., the use of Scala features such as implicit conversion \cite{pimp}.

The section presenting the case class representation of queries already revealed which primitives and operations are supported by EventScala.
In the listings \ref{lst:dsl_leaf}, \ref{lst:dsl_unary}, \ref{lst:dsl_binary} and \ref{lst:dsl_nested}, it will be shown how the DSL can be used to express queries made up of these primitives and operators, i.e., how the DSL can be used to express leaf, unary and binary queries.

\begin{lstlisting}[
caption={Primitives, i.e., leaf queries},
label={lst:dsl_leaf}]
// Subscription to a stream
// of events of type `Int` from A
val stream1: Query1[Int] =
  // Here, the type has to be explicitly annotated:
  stream[Int]("A")

// Subscription to a stream
// of events of type `String, String` from B
val stream2: Query2[String, String] =
  stream[String, String]("B")

// Subscription to two streams
// of events of type `Int` and `Boolean`, respectively,
// with the CEP operator `sequence` applied to them
val sequence1: Query2[Int, Boolean] =
  // Here, the types have to be explicitly annotated:
  sequence(
    nStream[Int]("C") ->
    nStream[Boolean]("D"))

// Subscription to two streams
// of events of type `Int, Int` and `Int`, respectively,
// with the CEP operator `sequence` applied to them
val sequence2: Query3[Int, Int, Int] =
  sequence(
    nStream[Int, Int]("E") ->
    nStream[Int]("F"))
\end{lstlisting}

\begin{lstlisting}[
caption={Application of unary operators, i.e., unary queries},
label={lst:dsl_unary}]
// Application of the SP operator `where`
// to `stream1` (`Query1[Int]`)
val filter1: Query1[Int] =
  stream1.where(_ % 2 == 0)
  // Alternatively: `stream1 where (_ % 2 == 0)`

// Application of the SP operator `where`
// to `sequence2` (`Query3[Int, Int, Int]`)
val filter2: Query3[Int, Int, Int] =
  sequence2.where((e1, _, e3) => e1 < e3)

// Application of the SP operator `dropElem2`
// to `stream2` (`Query2[String, String]`)
val dropElem1: Query1[String] =
  stream2.dropElem2()
  // Alternatively: stream2 dropElem2()

// Application of the SP operator `dropElem1`
// to `sequence1` (`Query2[Int, Boolean]`)
val dropElem2: Query1[Boolean] =
  sequence1.dropElem1()

// Application of the SP operator `selfJoin`
// to `stream2` (`Query2[String, String]`)
val selfJoin1: Query4[String, String, String, String] =
  stream2.selfJoin(
    slidingWindow(42.instances), // Alternatively: `42 instances`
    tumblingWindow(42.seconds))  // Alternatively: `42 seconds`

// Application of the SP operator `selfJoin`
// to `sequence1` (`Query2[Int, Boolean]`)
val selfJoin2: Query4[Int, Boolean, Int, Boolean] =
  sequence1.selfJoin(
    tumblingWindow(42.instances),
    slidingWindow(42.seconds))
\end{lstlisting}

\begin{lstlisting}[
caption={Application of binary operators, i.e., binary queries},
label={lst:dsl_binary}]
// Application of the SP operator `join`
// to `stream1` (`Query1[Int]`)
// and `stream2` (`Query2[String, String]`)
val join1: Query3[Int, String, String] =
  stream1.join(
    stream2,
    slidingWindow(42.instances),
    tumblingWindow(42.seconds))

// Application of the SP operator `join`
// to `sequence1` (`Query2[Int, Boolean]`)
// and `stream2` (`Query2[String, String]`)
val join2: Query5[Int, Boolean, Int, Int, Int] =
  sequence1.join(
    sequence2,
    slidingWindow(42.instances),
    tumblingWindow(42.seconds))

// Application of the CEP operator `and`
// to `stream2` (`Query2[String, String]`)
// and `stream1` (`Query1[Int]`)
val conjunction1: Query3[String, String, Int] =
  stream2.and(stream1)
  // Alternatively: `stream2 and stream1`

// Application of the CEP operator `and`
// to `sequence1` (`Query2[Int, Boolean]`)
// and `sequence2` (`Query3[Int, Int, Int]`)
val conjunction2: Query5[Int, Boolean, Int, Int, Int] =
  sequence1.and(sequence2)
  // Alternatively: `sequence1 and sequence2`

// Application of the CEP operator `or`
// to `stream1` (`Query1[Int]`)
// and `stream2` (`Query2[String, String]`)
val disjunction1: Query2[Either[Int, String], Either[X, String]] =
  stream1.or(stream2)
  // Alternatively: `stream1 or stream2`

// Application of the CEP operator `or`
// to `sequence2` (`Query3[Int, Int, Int]`)
// and `sequence1` (`Query2[Int, Boolean]`)
val disjunction2: Query3[Either[Int, Int], Either[Int, Boolean], Either[Int, X]] =
  sequence2.or(sequence1)
  // Alternatively: `sequence1 or sequence2`
\end{lstlisting}

\begin{lstlisting}[
caption={Nested queries},
label={lst:dsl_nested}]
// Nested application
// of 3 unary and 3 binary operators
// to 4 primitives
val nested1: Query3[Either[Int, String], Either[Int, X], Either[Float, X]] =
  stream[Int]("A")
    .join(
      stream[Int]("B"),
      slidingWindow(2.seconds),
      slidingWindow(2.seconds))
    .where(_ < _)
    .dropElem1()
    .selfJoin(
      tumblingWindow(1.instances),
      tumblingWindow(1.instances))
    .and(stream[Float]("C"))
    .or(stream[String]("D"))

// Nested application
// of 2 binary operators
// to 3 (!) primitives
val nested2: Query4[Int, Int, Float, String] =
  stream[Int]("A")
    .and(stream[Int]("B"))
    .join(
      sequence(
        nStream[Float]("C") ->
        nStream[String]("D")),
      slidingWindow(3.seconds),
      slidingWindow(3.seconds))
\end{lstlisting}

Furthermore, the section presenting the case class representation of queries also revealed that EventScala supports queries to be annotated with QoS requirements, i.e., \lstinline{FrequencyRequirement}s and  \lstinline{LatencyRequirement}s.
As already depicted, every (sub-)query can be annotated an arbitrary amount of such requirements, no matter how deeply they are nested.
Listing \ref{lst:dsl_qos} demonstrates how QoS requirements can be expressed using the DSL.
In it, the query  \lstinline{nested1} from listing \ref{lst:dsl_nested} (or rather two of its subqueries) are annotated with requirements.

\begin{lstlisting}[
caption={Nested queries that specify QoS requirements},
label={lst:dsl_qos}]
val nested1WithQos: Query3[Either[Int, String], Either[Int, X], Either[Float, X]] =
  stream[Int]("A")
  .join(
    stream[Int]("B"),
    slidingWindow(2.seconds),
    slidingWindow(2.seconds))
  .where(_ < _)
  .dropElem1(
    // `LatencyRequirement`
    latency < timespan(1.milliseconds) otherwise { (nodeData) =>
      println(s"Events reach node `${nodeData.name}` too slowly!") })
  .selfJoin(
    tumblingWindow(1.instances),
    tumblingWindow(1.instances),
    // `FrequencyRequirement`s
    frequency > ratio( 3.instances,  5.seconds) otherwise { (nodeData) =>
      println(s"Node `${nodeData.name}` emits too few events!") },
    frequency < ratio(12.instances, 15.seconds) otherwise { (nodeData) =>
      println(s"Node `${nodeData.name}` emits too many events!") })
  .and(stream[Float]("C"))
  .or(stream[String]("D"))
\end{lstlisting}

At this point is becomes apparent why the definition of QoS requirements in EventScala's DSL (and, by extionsion, EventScala's case class representation) is platform-specific, i.e., specific to EvenScala's execution graph.
As previously mentioned, each query (and, in turn, each of its subqueries) will be mapped to one processing node when run by the execution graph.
Whenever one of the requirements of a query cannot be met during run-time, the callback closure that was specified as part of the requirement is called.
This closure is invoked with run-time data about the respective processing node, which is represented by an instance of the case class `NodeData`.
This is exactly what lies behind the parameters called \lstinline{nodeData} in listing \ref{lst:dsl_qos}.

Nevertheless, when examining queries that are expressed using the DSL (such as the ones listed above), many advantages over expressing queries as unstructured strings become apparent, including the following:

\begin{description}

\item[Syntax]
Obviously but nevertheless very important is the fact that syntactically incorrect queries would fail to compile instead of causing runtime errors.
For example, forgetting the dot before adding another method call to the chain or misspelling a method's name would cause compilation to fail.

\item[Type-safety]
The type of a query expressed using the DSL always encodes the number and types of the elements of the events of the stream represented by it, e.g., a query of type \lstinline{Query2[Int, String]} represents a stream of events with 2 elements of type \lstinline{Int} and \lstinline{String}, respectively.
This information is used to provide static safeguards against a variety of malformed queries, for example:

\begin{itemize}

\item
Type-safety of the \lstinline{filter} operator:
The \lstinline{where} method takes a Scala closure that represents the filter predicate.
The number and types of the parameters of that closure have to match the number and types of the elements of the events of the stream that is represented by the respective query.
For example, given a query of type \lstinline{Query2[Int, String]}, the programmer has to supply a closure with exactly 2 parameters of type \lstinline{Int} and \lstinline{String}, respectively.
By extension, it is guaranteed that within the closure's body, these parameters are treated as an \lstinline{Int} and a \lstinline{String}, respectively, e.g., calling the \lstinline{String} method \lstinline{capitalize} on the second parameter would cause a compile-time error.

\item
Type-safety of the \lstinline{dropElem} operator:
Which ones of the \lstinline{dropElem} methods are available depends on the number of elements of the events of the stream represented by a given query.
For example, given a \lstinline{Query1}, not one \lstinline{dropElem} method can be called.
Given a \lstinline{Query2}, to provide another example, \lstinline{dropElem1} or \lstinline{dropElem2} maybe used.
Calling \lstinline{dropElem3} on it would, however, result in a compile-time error.

\item
Type-safety of the operators \lstinline{selfJoin}, \lstinline{join} and \lstinline{and}:
Given that EventScala only supports up to 6 elements per event, the DSL does not allow for the operators \lstinline{selfJoin}, \lstinline{join} and \lstinline{and} to be applied to two queries that represent streams for which the sum of the numbers of elements per event succeeds 6.
For example, when calling the \lstinline{join} method on a \lstinline{Query4}, only a \lstinline{Query1} or a \lstinline{Query2} can be passed to it representing the second operand of the \lstinline{join} operator.

\end{itemize}

\item[Tooling]
As the DSL is an internal DSL with Scala being its host language, every query expressed in it is also valid Scala.
As a consequence, IDEs and other tools that support Scala can also be leveraged when expressing queries using the DSL.
For example, one could benefit from the static safeguards listed above without ever manually hitting the compile button, as IDEs such as JetBrains' IntelliJ IDEA \cite{idea} continuously perform static analysis while typing.

\end{description}

Obviously, this list of advantages could have been presented earlier, i.e., in the section on EventScala's case class representation of queries.
All of the listed benefits also apply to the case class representation, since the DSL can be viewed as merely syntactic sugar for it.

Finally, as the DSL's usage has been demonstrated and its advantages have been pointed out, the remainder of this section discusses how it is implemented, i.e., it is described which patterns and Scala features are leveraged.

In EventScala's DSL, operators are represented by methods.
It might look as if these methods were defined on the traits \lstinline{Query1}, \lstinline{Query2}, ..., \lstinline{Query6}.
Assuming a value \lstinline{q} of type \lstinline{Query2}, one could, for example, write \lstinline{q.dropElem1()}, which suggests that \lstinline{dropElem1} is a method implemented by \lstinline{Query2}.
This would, however, violate the separation of data and logic.
Therefore, it is to be stressed that \lstinline{Query2}--along with every trait or case class that is part of EventScala's case class representation--does not come with any logic whatsoever, i.e., no methods are defined or implemented.

In EventScala's DSL, operators are represented by methods.
It might look as if these methods were defined on the traits \lstinline{Query1}, \lstinline{Query2}, ..., \lstinline{Query6}.
Assuming a value \lstinline{q} of type \lstinline{Query2}, one could, for example, write \lstinline{q.dropElem1()}, which suggests that \lstinline{dropElem1} is a method implemented by \lstinline{Query2}.
This would, however, violate the separation of data and logic.
Therefore, it is to be stressed that \lstinline{Query2}--along with every trait or case class that is part of EventScala's case class representation--does not come with any logic whatsoever, i.e., no methods are defined or implemented.

In order to make method calls such as \lstinline{q.dropElem1()} possible, the DSL heavily relies on an advanced language feature called implicit conversion.
In a blog post called ``Pimp my Library'' \cite{pimp}, Martin Odersky, the original designer of the Scala programming language, explains this feature.
In this context, it is sufficient to understand the following use case: Whenever a value of type \lstinline{X} is required but instead a value of type \lstinline{Y} is being supplied, the compiler tries to find a function that is capable of converting the \lstinline{Y} value to a \lstinline{X} value.
For this to work, the function has to be in scope, it has be marked with the \lstinline{implicit} keyword and its signature has to be \lstinline{Y => X}.
As an example, Odersky introduces \lstinline{x} to be of type \lstinline{Array[Int]} and then assigns \lstinline{x} to \lstinline{v}, a variable of type \lstinline{String}.
Obviously, this would normally result in a compile-time error.
However, it does not, since the function depicted in listing \ref{lst:implicit} is in scope:

\begin{lstlisting}[
caption={Implicit conversion function},
label={lst:implicit}]
implicit def array2string[T](x: Array[T]) = x.toString
\end{lstlisting}

At this point it is obvious why method calls such as \lstinline{q.dropElem1()} do not result in a compile-time error:
\lstinline{q} is of type \lstinline{Query2}, which neither defines nor implements the method \lstinline{dropElem1}.
However, there is a case class \lstinline{Query2Helper} which does have this method as well as an implicit conversion function that takes a \lstinline{Query2} and returns a \lstinline{Query2Helper}.
Needless to say, for each trait \lstinline{Query1}, \lstinline{Query2}, ..., \lstinline{Query6}, there is a case class \lstinline{Query1Helper}, \lstinline{Query2Helper}, ..., \lstinline{Query6Helper}, respectively, as well as a respective implicit conversion function in place.

This is basically a simplification of an approach proposed by Debasish Ghosh in his book ``DSLs in Action'' \cite{Ghosh:2010:DA:1965333}.
In chapter 6.4 (``Building a DSL that creates trades''), he uses a ``[s]equence of implicit conversions'' and the ``subsequent creation of helper objects'' to construct a tuple that represents something called a fixed income trade.
This pattern can be described as follows:
The DSL should be used to construct a tuple.
The tuple's first element should be of type \lstinline{A}, the second one of type \lstinline{B}, the third one of type \lstinline{C}, etc.
Helper classes \lstinline{AHelper}, \lstinline{ABHelper}, \lstinline{ABCHelper}, etc. as well as the respective implicit conversion methods with the signatures \lstinline{A => AHelper}, \lstinline{(A, B) => ABHelper}, \lstinline{(A, B, C) => ABCHelper}, etc. are defined.
\lstinline{AHelper} has a \lstinline{method1} that takes a \lstinline{B} and returns an \lstinline{(A, B)}, \lstinline{ABHelper} has a \lstinline{method2} that takes a \lstinline{C} and returns an \lstinline{(A, B, C)}, and so forth.
This pattern allows for expressions such as \lstinline{a method1 b method2 c /* ... */} (with \lstinline{a} being an \lstinline{A}, \lstinline{b} being a \lstinline{B}, and so forth).
As said, Ghosh presents this pattern along with an example DSL is based upon it.
He demonstrates how the expression \lstinline{200 discount_bonds IBM for_client NOMURA on NYSE at 72.ccy(USD)} can be used to obtain a tuple that represents a fixed income trade, i.e., \lstinline{((72, USD), NYSE, NOMURA, 200, IBM)}.

Another Scala feature that the DSL heavily relies upon is operator overloading.
Technically, however, Scala does not support operator overloading, as it does not even have operators.
Instead, what seem to be operators are actually methods.
The arithmetic operator \lstinline{+} that is defined over two \lstinline{Int}s, for instance, is simply a method \lstinline{abstract def +(x: Int): Int} of the abstract class \lstinline{Int}.
As such, the two expressions \lstinline{40 + 2} and \lstinline{40.+(2)} are actually equivalent.
With many characters being legal identifiers that can be used as method names, e.g., \lstinline{+}, \lstinline{>}, \lstinline{<}, \lstinline{|}, overloading an operator in Scala is nothing more than defining a method.
This feature is used throughout the DSL.
For example, in order to construct some \lstinline{FrequencyRequirement}, on might write \lstinline{frequency > ratio(/* ... */) /* ... */}.
Calling the function \lstinline{frequency} returns a case object called \lstinline{FrequencyHelper}, which defines a bunch of methods, including \lstinline{>}, \lstinline{>=}, \lstinline{<}, \lstinline{<=}, etc., all of which take one argument of type \lstinline{Ratio}.

Lastly, variable-length argument lists (also known as varargs) constitute yet another Scala feature that is used throughout the DSL.
Varargs are, for instance, used to syntactically reflect the fact that queries in EventScala can be annotated with zero or more QoS requirements.
To this end, the type of the last parameter of every method of the DSL that returns a query is \lstinline{Requirement*}.
The \lstinline{stream[A]} method, for example, specifies two parameters, i.e., \lstinline{publisherName} of type \lstinline{String} and \lstinline{requirements} of type \lstinline{Requirement*}.
Thus, this method might be supplied with no requirement, e.g., \lstinline{stream[Int]("X")}, with one requirement, e.g., \lstinline{stream[Int]("X", r1)}, with two requirements, e.g., \lstinline{stream[Int]("X", r1, r2)}, etc. (with \lstinline{r1}, \lstinline{r2}, etc. being of type \lstinline{Requirement}).
If the DSL would not rely on varargs but simply use \lstinline{Set[Requirement]} as the type of the \lstinline{requirement} parameter--as it is the case in the case class representation--these method calls would look much more verbose:
\lstinline{stream[Int]("X", Set.empty)}, \lstinline{stream[Int]("X", Set(r1))}, \lstinline{stream[Int]("X", Set(r1, r2))}, etc.

\subsection{Execution Graph}
\label{sec:execution_graph}

EventScala does not only offer a type-safe case class representation of EP queries and a DSL to generate the former, it does also offer a way to execute such queries.
It is EventScala's execution graph (or just graph) that allows for running queries in a--as the title of this thesis suggests--distributed fashion.

This section is structured as follows.
The execution graph is based on the Scala toolkit Akka and, as such, on the Actor Model.
Even though this is not the place to cover either of them in depth, the first part of this section will introduce the Actor Model and Akka to the extent necessary.
Afterwards, it is laid out why Akka appears to be a good fit for implementing the execution graph.
Lastly, the implementation of the execution graph is described.

EventScala's execution graph is implemented using the Scala framework Akka.
Akka is based on the Actor Model \cite{Hewitt:1973:UMA:1624775.1624804}.
Accrding to the official documentation \cite{akka}, actors ``give you'' ``high-level abstractions for distribution, concurrency and parallelism'' as well as an ``[a]synchronous, non-blocking and highly performant message-driven programming model''.
According to Akka's documentation, concurrency means ``that two tasks are making progress''--independently from each other--although they do not necessarily to so at the same time, i.e., ``they might not be executing simultaneously''.
As as example, time slicing is mentioned.
Parallelism is then described to be the case ``when the execution can be truly simultaneous''.
Furthermore, a method call is described as being synchronous ``if the caller cannot make progress until the method returns''.
A method call is considered asynchronous when it ``allows the caller to progress'' right after issuing the call, as the completion of the method is signaled through, say, the invocation of a callback closure.

Using Akka (and, by extension, the Actor Model), applications are essentially built by creating hierarchies of actors that send and receive messages.
According to Akka's documentation, actors are ``container[s]'' for state, behavior, a mailbox, child actors and a supervision strategy.
These five characteristics are then described in detail.
Below, I summarized from the documentation what is important to know about these characteristics in the context of this thesis.

\begin{description}

\item[State]
An actor is a stateful abstraction.
Therefore, an actor typically contains variables reflecting ``possible states the actor may be in'', e.g., a variable representing a ``set of listeners'' or ``pending requests''.
Most importantly, this data is safeguarded from ``corruption by other actors''.
Furthermore, ``conceptually'', each actor is represented by its own thread, which is also ``completely shielded from the rest of the system''.

\item[Behavior]
Whenever an actor processes a message, it triggers the actor to behave in a certain way.
Behavior is described as a ``function which defines the actions to be taken in reaction to the message''.

\item[Mailbox]
As it is stated that it is ``[a]n actor's purpose'' to process messages, its mailbox, ``which connects sender and receiver'', deserves special attention.
An actor's mailbox enqueues the messages directed to it ``in the time-order of send operations''.
As a result of this, ``messages sent from different actors may no have a defined order at runtime''.
On the other hand, however, if the mailbox only contains messages from one sender, they are ensured to be in the same order.

\item[Child actors]
Actors may create child actors which they will then ``automatically supervise''.

\item[Supervision strategy]
Lastly, an actor embodies a ``strategy for handling faults of its children''.
As EventScala is a research project that does not concern itself with fault tolerance, this will not be mentioned again.

\end{description}

It is to be stressed that while actors ``are objects which encapsulate state and behavior'', ``they communicate exclusively by exchanging [immutable] messages''.
Therefore, fields and methods defined by an actor cannot be accessed in a direct, synchronous fashion.
Instead, an actor can only be interacted with asynchronously, i.e., through messages.
To the best of my understanding, this is key when it comes to how Akka tries to take the pain out of concurrent and asynchronous programming:
Even though many actors might run concurrently and communicate asynchronously, the code that is defined within each actor can be thought of as being executed sequentially and the communication between actors through immutable messages works without any kind of shared memory, rendering error-prone primitives such as locks unnecessary.

In section 2.1, characteristics of EDAs \cite{Chandy:2009:EPD:1594754} have been listed.
I found that these directly apply to Akka and, by extension, the Actor Model, too.
This is Akka is such a natural fit for implementing an EP engine.

\begin{description}

\item[Individuality]
An actor sends out each message individually.

\item[Push]
An actor sending out a message is never caused by some kind of request.
(It could, however, be the reaction to some message previously received by the actor, which does not constitute a request, though, due to the last characteristic, i.e., ``free of command''.)

\item[Immediacy]
An actor reacts to a message immediately after receiving it.
(In fact, it could be stated that all it does is reacting to messages right after receiving them.)

\item[One-way]
By default, an actor neither acknowledges nor replies to a received message. (Of course, this behavior can be explicitly implemented.)

\item[Free of command]
An actor always decides how to react to a received message, said reaction is never dictated by the message.

\end{description}

The execution graph of a query consists of actors organized in a graph hierarchy.
In section 3.2, it has been described how a query in case class representation could be pictured as a graph.
It has already been pointed out then, that this conceptual graph directly corresponds to what EventScala's execution graph for that query would look like, i.e., it precisely resembles the hierarchy in which the actors of the respective execution graph are assembled.
In this conceptual graph, the outermost query has been depicted as the root node of the graph, its subquery as the child node of the root node, and so forth.
In an execution graph of a query, these nodes are actors.
Obviously, each actor represents either a primitive or an operator of the given query, i.e., either a \lstinline{LeafQuery}, \lstinline{UnaryQuery} or \lstinline{BinaryQuery}.
Actors representing primitives, i.e., \lstinline{LeafQueries}, constitute the leaves of the graph.
They receive messages, i.e., events, from so-called \lstinline{Publisher}s, which publish the events of the streams to which the primitives represent subscriptions.
An actor representing a primitive then passes up these events to its parent actor, which represents an operator, i.e., either a \lstinline{UnaryQuery} or a \lstinline{BinaryQuery}.
An actor representing an operator performs the respective (SP or CEP) operation on the the incoming stream(s) and sends the messages or events of the resulting stream up to its own parent actor.
Finally, the actor representing the root of the graph invokes a closure specified by the programmer with every event of its result stream.

As it would seem natural, the classes up that make EventScala's execution graph resemble the classes that make up its case class representation in their structure.
Accordingly, corresponding to the \lstinline{LeafQuery} trait there is a trait \lstinline{LeafNode}, corresponding to \lstinline{UnaryQuery} there is \lstinline{UnaryNode} and corresponding to \lstinline{BinaryQuery} there is \lstinline{BinaryNode}.
The traits \lstinline{LeafNode}, \lstinline{UnaryNode} and \lstinline{BinaryNode} extend the \lstinline{Node} trait, which, in turn, extends the \lstinline{Actor} trait.
As expected, the classes \lstinline{StreamNode} and \lstinline{SequenceNode} extend the \lstinline{LeafNode} trait, \lstinline{FilterNode}, \lstinline{DropElemNode} and \lstinline{SelfJoinNode} extend \lstinline{UnaryNode} and \lstinline{JoinNode}, \lstinline{ConjuctionNode} and \lstinline{DisjunctionNode} extend \lstinline{BinaryNode}.

Figure \ref{fig:graph} shows the execution graph of the query defined in listing \ref{lst:query} (depicted in figure \ref{fig:query}).

\begin{figure}
\caption{Execution graph of the query defined in listing \ref{lst:query}}
\label{fig:graph}
\includegraphics[width=0.5\textwidth]{images/graph.png}
\centering
\end{figure}

Some classes, e.g., \lstinline{JoinNode}, extend a trait called \lstinline{EsperEngine}, while others, e.g., \lstinline{FilterNode}, do not.
The actors extending \lstinline{EsperEngine} are essentially equipped with their own instance of the EP engine Esper, which they use to perform the respective operation they represent.
This approach has to has two advantages.
At first, by relying on Esper's implementation of more complex operators, e.g., \lstinline{join}, a (possibly incorrect) implementation of such operators does not have to be provided.
Moreover, resolving the semantic ambiguity of the \lstinline{sequence} as well as the \lstinline{and} operator is also taken care of by Esper's implementation.
It is to be noted that some of the code of the \lstinline{EsperEngine} trait was inspired by a Lightbend Activator Template called ``CEP with Akka and Esper or Streams'' \cite{akkacep}.

Obviously, the execution graph of a query is created dynamically at run-time.
At first, a \lstinline{Node} corresponding to the outermost query of the respective query is created as a top-level actor of an \lstinline{ActorSystem}.
From then on, the graph builds up recursively, i.e., a \lstinline{UnaryNode} will create a child actor that corresponds to the one subquery of the \lstinline{UnaryQuery} which it represents.
Likewise, a \lstinline{BinaryNode} will create create two child actors that correspond to the two subqueries of the \lstinline{BinaryQuery} which it represents.
\lstinline{LeafNode}s will issue \lstinline{Subscription}(s) to \lstinline{Publisher}(s).
When a \lstinline{Publisher} acknowledges a \lstinline{LeafNode}'s subscription, the \lstinline{LeafNode} either sends a \lstinline{Created} message to its parent actor, or--if it is the root actor of the graph--invokes a closure that is to be called as soon as the graph is built (which supplied by the programmer). \lstinline{UnaryNode}s and \lstinline{BinaryNode}s also either send a \lstinline{Created} message to their parent actors or call the closure as soon as all of their child actors have sent them the \lstinline{Created} message.

Finally, it is noteworthy that at run-time, events are represented by the classes \lstinline{Event1}, \lstinline{Event2}, ..., \lstinline{Event6}, all of which extend the trait \lstinline{Event}.
\lstinline{Publisher}s pass up \lstinline{Event}s to the leaves of the execution graph of a query, and, within this graph, \lstinline{Node}s pass them up to their parent actors.
Unlike their counterparts \lstinline{Query1}, \lstinline{Query2}, ..., \lstinline{Query6}, \lstinline{Event}s do not have type parameters for each of their elements.
Instead, the elements of an \lstinline{Event} are of type \lstinline{Any}.
However, Akka actors are untyped anyway, i.e., actors receive any message and can send any message to any actor.

\subsection{Quality of Service}
\label{sec:qos}

As the title of this thesis suggests, EventScala represents a QoS-oriented approach to EP.
As such, it allows not only for QoS requirements to be defined over queries but also for their enforcement at run-time.
To this end, EventScala's execution graph features so-called QoS monitors, which are concerned with surveiling an actor's performance as well as reacting when a requirement is not met.

This section is structured as follows.
At first, the notion of monitors is introduced conceptually.
Then, implementation details are laid out.
Lastly, the two exemplary monitors that come with EventScala are described.

Conceptually, when picturing a query as a graph, QoS requirements can be defined over each node of that graph.
To be more precise, an arbitrary amount of \lstinline{FrequencyRequirement}s and \lstinline{LatencyRequirement}s can be defined over each node of the graph.
As this conceptual graph precisely resembles EventScala's execution graph of the same query, QoS requirements of a (sub-)query are being dealt with by the actor that represents that (sub-)query in the execution graph.
To this end, each actor has to monitor its performance, and, whenever a requirement is not being met, react to this circumstance by invoking a closure that has been specified along with the respective requirement.
(To this end, both case classes \lstinline{FrequencyRequirement} and \lstinline{LatencyRequirement} specify a field \lstinline{callback}.)
This closure might even carry out curative measures, as its arguments include the respective actor's \lstinline{ActorContext}, which embodies run-time information about it.

Informally speaking, EventScala's execution graph requires the programmer to provide reference to one class representing a frequency monitor as well as one to class representing a latency monitor.
At run-time, each actor of an execution graph gets exactly one instance of both of them, regardless of whether or not the query that the actor represents specifies any QoS requirements.
As a consequence, at run-time, each actor has one frequency monitor instance as well as one latency monitor instance.

Technically speaking, EventScala's execution graph requires the programmer to provide two classes that extend the \lstinline{MonitorFactory} trait, one for frequency monitoring and one for latency monitoring.
A \lstinline{MonitorFactory} can create instances of classes that extend one of the traits \lstinline{LeafNodeMonitor}, \lstinline{UnaryNodeMonitor} and \lstinline{BinaryNodeMonitor}.
Thus, at run-time, a \lstinline{LeafNode} will have one \lstinline{LeafNodeMonitor} for frequency monitoring as well another \lstinline{LeafNodeMonitor} for latency monitoring.
The former will have been created by the factory supplied for frequency monitoring and the latter will have been created by the factory supplied for latency monitoring.
Analogously, the same is true for \lstinline{UnaryNode}s and \lstinline{BinaryNode}s.

EventScala has been designed to make it easy for programmers to implement their own monitors.
To do so, one has to provide four classes that implement the four traits \lstinline{LeafNodeMonitor}, \lstinline{UnaryNodeMonitor}, \lstinline{BinaryNodeMonitor} as well as \lstinline{MonitorFactory}.
EventScala comes with one exemplary frequency monitor as well as with one exemplary latency monitor. The examplary frequency monitor, for example, is comprised of the following four classes:

\begin{itemize}

\item
\lstinline{AveragedFrequencyLeafNodeMonitor} extending the trait \lstinline{LeafNodeMonitor}

\item
\lstinline{AveragedFrequencyUnaryNodeMonitor} extending the trait \lstinline{UnaryNodeMonitor}

\item
\lstinline{AveragedFrequencyBinaryNodeMonitor} extending the trait \lstinline{BinaryNodeMonitor}

\item
\lstinline{AveragedFrequencyMonitorFactory} extending the trait \lstinline{MonitorFactory}

\end{itemize}

However, the question remains how these monitors actually surveil the performance of the actor they are associated with.
Conceptually, each monitor implements so-called lifecycle methods, i.e., hooks into the respective actor's lifecycle.
(This approach has been inspired by React, Facebook's JavaScript library for building UIs \cite{react}, in which so-called components have so-called lifecycle methods ``that you can override to run code at particular times in the process'' \cite{reactcomponent}.)
\lstinline{LeafNodeMonitor}, \lstinline{UnaryNodeMonitor} and \lstinline{BinaryNodeMonitor} all specify three methods that need to be implemented by extending classes:

\begin{itemize}

\item
\lstinline{onCreated}

\item
\lstinline{onEventEmit}

\item
\lstinline{onMessageReceive}

\end{itemize}

As the names of these methods suggest, the respective actors invoke them at certain times during their lifecycle.
\lstinline{onCreated} is being called only once, right after all of the actor's children have issued a \lstinline{Created} message to it.
\lstinline{onEventEmit} is being invoked whenever the actor emitted an event.
\lstinline{onMessageReceive} is being called whenever the actor receives a message that has not been generated by EventScala's execution graph, as it might have been sent by another monitor.
(This way, communication between the monitors of the actors of the graph is facilitated.)
Obviously, whenever \lstinline{onEventEmit} is called, it is passed the respective event.
Likewise, whenever \lstinline{onMessageReceive} is called, it is passed the respective message.
Furthermore, depending on the type of the respective actor, when being invoked, all three methods are always passed either an instance of the \lstinline{LeafNodeData} case class, an instance of the \lstinline{UnaryNodeData} case class or an instance of the \lstinline{BinaryNodeData} case class.
All of these contain the name of the actor as a \lstinline{String} as well as its \lstinline{ActorContext}.
\lstinline{UnaryNodeData} and \lstinline{BinaryNodeData} also contain an \lstinline{ActorRef}, i.e., a reference to an actor, for each of their child actors.

It is to be noted that this approach constitutes a powerful way to surveil the performance of an actor and, by extension, the performance of the entire execution graph.
For each metric (frequency and latency), each actor has one monitor.
A monitor contains code that is being executed repeatedly throughout the lifecycle of an actor.
The methods embodying this code are even invoked with run-time information about the actor.
Moreover, monitors are able to communicate with each other using messages.
As monitors are nothing but classes extending one of the traits \lstinline{LeafNodeMonitor}, \lstinline{UnaryNodeMonitor} or \lstinline{BinaryNodeMonitor}, they can leverage the capabilities of Scala classes, e.g., keeping state in field variables of the class.

As mentioned before, EventScala comes with one exemplary frequency monitor as well as one exemplary latency monitor.
The following two paragraphs will informally describe their implementation.

The exemplary frequency monitor is comprised of four classes, which are all defined in one file called\newline \lstinline{AverageFrequencyMonitor.scala}.
Given an interval, e.g., 30 seconds, a monitor uses a field variable to keep track of the number of events that have been emitted by the actor it surveils.
If a \lstinline{FrequencyRequirement} has been defined over the query that the actor represents, e.g., \lstinline{frequency > ratio(2.instances, 5.seconds)}, a monitor calculates an average of how many events have been emitted in the time frame specified by the requirement.
E.g., if the actor emitted 12 events in the last 30 seconds, the monitor would calculate that--on average--the actor emits 2 events in 5 seconds.
(This would not satisfy the requirement, so the monitor would invoke the closure of the requirement.)

The exemplary latency monitor is also comprised of four classes, all of which are located in one file called \lstinline{PathLatencyMonitor.scala}.
This is a more complex monitor as it leverages communication between the monitor instances using messages.
Periodically, each monitor calculates the so-called path latency of the respective actor.
Given all paths that connect the actor in question to a \lstinline{LeafNode}, path latency denotes the time it takes a message (or event) to travel along the slowest of these paths.
(See figure \ref{fig:path_latency}.)
Obviously, the path latency of a \lstinline{LeafNode} is always 0.
In order to calculate it for \lstinline{UnaryNode}s and \lstinline{BinaryNode}s, each monitor surveiling a \lstinline{UnaryNode} or a \lstinline{BinaryNode} periodically sends a message to its child's or its children's monitor(s), respectively, which will respond immediately.
The time that passes between sending the message and receiving the response is being divided by 2 in order to approximate the time it takes for an event to travel from a child actor to the actor in question.
(This value is referred to as child latency).
Obviously, child latency equals path latency if the child actor in question is a \lstinline{LeafNode}.
Path latency values are always advertised to the parent actor's monitor.
A \lstinline{UnaryNode}'s monitor can simply add the advertised path latency of its child actor to the child latency in order to obtain its own path latency.
A \lstinline{BinaryNode}'s monitor has to do so twice, i.e., it has to add the advertised path latency of child actor 1 to the child latency of child actor 1, and then do so again for child actor 2.
The greater of the two resulting values will be adopted as the \lstinline{BinaryNode}'s path latency.
If a \lstinline{LatencyRequirement} has been defined over the query that an actor represents, the requirement's closure will be invoked if the calculated path latency does not satisfy the requirement.
Figure \ref{fig:path_latency} illustrates how to calculate path latency:
Of the 3 paths that connect actor \lstinline{X} to a \lstinline{LeafNode}, the one indicated by the thick, red edges is the slowest.
Therefore, it is used to calculate \lstinline{X}'s path latency, which is 1 ms + 3 ms = 4 ms.

\begin{figure}
\caption{Path latency illustration}
\label{fig:path_latency}
\includegraphics[width=0.5\textwidth]{images/path_latency.png}
\centering
\end{figure}

\newpage

\section{Simulation}
\label{sec:simulation}

In order to showcase its capabilities, EventScala comes with an exemplary set up simulating a real-world use case.
It is comprised of three main components:

\begin{itemize}

\item
4 sample \lstinline{Publisher}s representing four streams that can be subscribed to

\item
2 sample queries expressed using the DSL

\item
1 sample configuration for an execution graph

\end{itemize}

In this section, all three components are described in detail.
Then, the output that is being generated when running the simulation is discussed.

In EventScala, a publisher represents a primitive stream that can be subscribed to.
To this end, the specifications of the \lstinline{Publisher} trait--which extends the \lstinline{Actor} trait--include that a publisher has to maintain a set of publishers.
On top of that, EventScala defines a case class \lstinline{RandomPublisher} publishes one event every x milliseconds, with x being a pseudo-random \lstinline{Integer} between 0 (inclusive) and 5000 (exclusive).
A \lstinline{RandomPublisher} takes a closure of type \lstinline{Integer => Event}, which it invokes in order to obtain the \lstinline{Event} instances it publishes.
To obtain the first event, it calls the closure with \lstinline{0}, to invoke the second event, it calls the closure with \lstinline{1}, and so on.
In the simulation, there are 4 \lstinline{RandomPublisher}s called ``A'', ``B'', ``C'' and ``D'', representing streams of the types \lstinline{Stream1[Int]}, \lstinline{Stream1[Int]}, \lstinline{Stream1[Float]} and \lstinline{Stream1[String]}, respectively.
(See listing \ref{lst:sim_publishers}.)

\begin{lstlisting}[
caption={The four \lstinline{RandomPublisher}s of the simulation},
label={lst:sim_publishers}]
val publisherA: ActorRef = actorSystem.actorOf(Props(
  RandomPublisher(id => Event1(id))), "A")
val publisherB: ActorRef = actorSystem.actorOf(Props(
  RandomPublisher(id => Event1(id * 2))), "B")
val publisherC: ActorRef = actorSystem.actorOf(Props(
  RandomPublisher(id => Event1(id.toFloat))), "C")
val publisherD: ActorRef = actorSystem.actorOf(Props(
  RandomPublisher(id => Event1(s"String($id)"))), "D")
\end{lstlisting}

The two sample queries \lstinline{query1} and \lstinline{query2} (listing \ref{lst:sim_queries}) are expressed using the DSL and should not require any further explanation.
\lstinline{query1} will not be shown below as it is the same query that is shown in listing \ref{lst:dsl_qos}.

\begin{lstlisting}[
caption={\lstinline{query2} of the simulation},
label={lst:sim_queries}]
val query2: Query4[Int, Int, Float, String] =
  stream[Int]("A")
  .and(stream[Int]("B"))
  .join(
    sequence(
      nStream[Float]("C") -> nStream[String]("D"),
      frequency > ratio(1.instances, 5.seconds) otherwise { (nodeData) =>
        println(s"PROBLEM:\tNode `${nodeData.name}` emits too few events!") }),
    slidingWindow(3.seconds),
    slidingWindow(3.seconds),
    latency < timespan(1.milliseconds) otherwise { (nodeData) =>
      println(s"PROBLEM:\tEvents reach node `${nodeData.name}` too slowly!") })
\end{lstlisting}

Lastly, the simulation comes with a sample configuration for an execution graph of either \lstinline{query1} and \lstinline{query2}.
(Shown in listing \ref{lst:sim_conf} is the version for \lstinline{query1}).
It is being specified that the exemplary monitors, i.e., \lstinline{AverageFrequencyMonitor} and \lstinline{PathLatencyMonitor}, will be used for frequency and latency monitoring, respectively.
The former is set to perform its calculations every 15 seconds while the latter is set to do so every 5 seconds.
Both of them are set to log their calculations to the console.
The closure that will be invoked when the graph has been created simply prints \lstinline{"STATUS:\tGraph has been created."} to the console, and the closure that will be called whenever the root actor produced an event simply prints said event to the console.
It is to be noted that the latter closure is type-safe, i.e., its type is \lstinline{Either[Int, String], Either[Int, X], Either[Float, X] => Any}.

\begin{lstlisting}[
caption={The execution graph configuration of the simulation},
label={lst:sim_conf}]
val graph: ActorRef = GraphFactory.create(
  actorSystem =             actorSystem,
  query =                   query1,
  publishers =              publishers,
  frequencyMonitorFactory = AverageFrequencyMonitorFactory  (interval = 15, logging = true),
  latencyMonitorFactory =   PathLatencyMonitorFactory       (interval =  5, logging = true),
  createdCallback =         () => println("STATUS:\tGraph has been created."))(
  eventCallback =           {
    case (Left(i1), Left(i2), Left(f)) => println(s"COMPLEX EVENT:\tEvent3($i1,$i2,$f)")
    case (Right(s), _, _)              => println(s"COMPLEX EVENT:\tEvent1($s)")
    // This is necessary to avoid warnings about non-exhaustive `match`:
    case _                             =>
  })
\end{lstlisting}

When being run for approximately 15 seconds (not including set up time) on a Lenovo ThinkPad X220i laptop with a Intel Core i3-2350M CPU @ 2.30 GHz * 2 processor, this simulation generates the console output like shown in listing \ref{lst:sim_out}.

\begin{lstlisting}[
caption={The console output of the simulation (Newlines were added)},
label={lst:sim_out}]
STATUS:         Graph has been created.
LATENCY:
  Events reach node `disjunction-1-conjunction-1-selfjoin-1-dropelem` after PT0.015S.
  (Calculated every 5 seconds.)
PROBLEM:
  Events reach node `disjunction-1-conjunction-1-selfjoin-1-dropelem` too slowly!
STREAM A:       Event1(1)
STREAM B:       Event1(2)
STREAM A:       Event1(2)
STREAM D:       Event1(String(2))
COMPLEX EVENT:  Event1(String(2))
STREAM C:       Event1(1.0)
COMPLEX EVENT:  Event3(2,2,1.0)
STREAM B:       Event1(4)
STREAM A:       Event1(3)
STREAM C:       Event1(2.0)
COMPLEX EVENT:  Event3(4,4,2.0)
LATENCY:
  Events reach node `disjunction-1-conjunction-1-selfjoin-1-dropelem` after PT0.0015S.
  (Calculated every 5 seconds.)
PROBLEM:
  Events reach node `disjunction-1-conjunction-1-selfjoin-1-dropelem` too slowly!
STREAM D:       Event1(String(3))
COMPLEX EVENT:  Event1(String(3))
STREAM C:       Event1(3.0)
STREAM B:       Event1(6)
STREAM D:       Event1(String(4))
COMPLEX EVENT:  Event1(String(4))
STREAM C:       Event1(4.0)
STREAM B:       Event1(8)
STREAM A:       Event1(4)
COMPLEX EVENT:  Event3(8,8,3.0)
STREAM C:       Event1(5.0)
STREAM B:       Event1(10)
COMPLEX EVENT:  Event3(10,10,5.0)
STREAM D:       Event1(String(5))
COMPLEX EVENT:  Event1(String(5))
LATENCY:
  Events reach node `disjunction-1-conjunction-1-selfjoin-1-dropelem` after PT0.0005S.
  (Calculated every 5 seconds.)
STREAM C:       Event1(6.0)
STREAM A:       Event1(5)
COMPLEX EVENT:  Event3(10,10,6.0)
STREAM B:       Event1(12)
STREAM B:       Event1(14)
STREAM A:       Event1(6)
STREAM C:       Event1(7.0)
COMPLEX EVENT:  Event3(12,12,7.0)
STREAM C:       Event1(8.0)
STREAM D:       Event1(String(6))
COMPLEX EVENT:  Event1(String(6))
LATENCY:
  Events reach node `disjunction-1-conjunction-1-selfjoin-1-dropelem` after PT0.0015S.
  (Calculated every 5 seconds.)
PROBLEM:
  Events reach node `disjunction-1-conjunction-1-selfjoin-1-dropelem` too slowly!
FREQUENCY:
  On average, node `disjunction-1-conjunction-1-selfjoin` emits 3 events every 5 seconds.
  (Calculated every 15 seconds.)
PROBLEM:
  Node `disjunction-1-conjunction-1-selfjoin` emits too few events!
FREQUENCY:
  On average, node `disjunction-1-conjunction-1-selfjoin` emits 9 events every 15 seconds.
  (Calculated every 15 seconds.)
\end{lstlisting}

It can be observed that publishers print the primitive events they publish to the console.
Likewise, the root node prints the complex events the graph produces to the console.
As expected, the latency monitor of the node \lstinline{disjunction-1-conjunction-1-selfjoin-1-dropelem} logged to the console four times, i.e., once after graph creation, once after 5 seconds, once after 10 seconds, and once after 15 seconds.
Also as expected, the frequency monitor of the node \lstinline{disjunction-1-conjunction-1-selfjoin} only logged to the console once, i.e., after 15 seconds.
Lastly, it is to be noted that the latency requirement has been met in 1 out of 4 times.
The two frequency requirements, however, are defined in a way that they can never both be met.
Accordingly, after 15 seconds, one of them was met (\lstinline{frequency < ratio(12.instances, 15.seconds)}) while the other one was not (\lstinline{frequency > ratio(3.instances, 5.seconds)}).

\newpage

\section{Conclusion}
\label{sec:conclusion}

\newpage

\printbibliography

\end{document}
